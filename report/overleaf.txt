\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{CV For Anomaly Detection In the Industrial Application\\}
\author{

\IEEEauthorblockN{Arman Alahyari, Anton Hinneck, Rahim Tariverdi, Iurii Katser, Viacheslav Kozitsin}
\IEEEauthorblockA{{Center for Energy Science and Technology, } \\
{Center for Computational and Data-Intensive Science and Engineering (CDISE)} \\
{Skolkovo Institute of Science and Technology (\textit{Skoltech})}\\
%Moscow, Russia \\
}
}

\maketitle

\begin{abstract}
Recently, the application of computer vision for anomaly detection has been under attention in several industrial fields. Two important examples of which are power transmission insulator and oil pipeline defect detection.  Failure of these elements could cause the interruption of the entire transmission system or widespread failure. Therefore, automated fault detection for these components could significantly decrease inspection time and the related cost. 
There are some gaps while dealing with the aforementioned tasks in the related literature. For instance, the existing studies only focus on one specific type of fault for insulators, and there are no studies to properly deal with the automated size of defect evaluation in the pipelines. Thus, in this work, we focus on alleviating these issues. Specifically, in doing so, we exploit recent convolutional neural network structures and proposed capable approaches aiming to acquire high performance considering the related metrics. The proposed approaches and their applicability are verified using real-world data-based simulations.  
\end{abstract}

\begin{IEEEkeywords}
Transmission Lines, Insulators, Oil Pipelines, Convolutional Neural Networks, Image Classification, Segmentation, Defect Detection.
\end{IEEEkeywords}

\section{Introduction}
Anomaly detection problems have a great importance in industrial applications, because anomalies usually represent faults, failures or the emergence of such. To detect these automatically, advanced analytic algorithms, including machine learning- and deep learning-based, can be applied. In this project, we investigate deep neural network performances in providing hindsight in practical industrial application. However, due to the broad existing application, we only have chosen two, yet in important section of energy industry, namely: detecting and classifying faulty insulators for power transmission system and defects detection in oil pipelines. Both these systems can span over thousands of kilometers, which makes manual inspection very costly. The rest of the paper is devoted to appraising computer vision (CV) techniques proficiency in real world industrial scale applications. It is worth mentioning that  the general goal of both tasks and the utilized networks are very similar, however due to the different nature of the chosen applications the details may vary which are properly covered and discussed in all sections of report where necessary.
Note that through the paper, the details regarding transmission line insulators maybe revered to as insulators or task I and regarding oil pipelines as pipelines or task II.
\subsection{Background and Motivation}
\subsubsection{Transmission line insulators}

Smart grid is a concept that is used to describe a novel structure for power grid where smart communication and control facilities should provide better reliability and resiliency toward the grid where operations become more automated \cite{a1,a2}.
Smart grids as a new design for power grids also involve three main sections of generation, transmission and distribution. There exists many challenges toward automation of all of these three sections. However, as transmission section normally cover several kilometers the induced challenge proceeds even more severe. 

Even though, at the first glance transmission lines maybe the most important component of a transmission grid considering insulation control rule, insulators also play an
important role as they mechanically secure wires in transmission sections . For instance, if any of the insulator becomes faulty or defected, it will directly influence  the total usage and the span life of transmission lines. Consequently, it is of great importance to detect insulator fault timely to guarantee the safety of transmission lines and as a result reaching a better reliability for the entire power grid \cite{a3}. 

Considering the long length of transmission grids manually inspecting their healthy operation for example through helicopters and human experts impose a great difficulty and huge time consumption. Thus, several experiments have tried to consider automating  inspecting power transmission
systems visual task \cite{a4,a5}. Specifically, considering the danger involved in the task for humans, unmanned aerial vehicles (UAVs) have proven to be a useful tool in the inspection of power transmission grid components. Fig. \ref{uav} shows a UAV while it is inspecting the transmission lines insulators.

Generally, the taken images through the inspection carried out by UAVs includes different backgrounds such as mountains, grass field, tower and etc which can vary related to the time of inspection as well. Thus, processing the taken images will be rather challenging an complicated.
\begin{figure}[!h]
\centering
  \includegraphics[width=\linewidth,trim={0cm 0 0 0cm},clip]{figs/uav2.jpg}
  %\includegraphics[width=\linewidth,trim={0cm 0 0 0cm},clip]{uav.jpg}
  \caption{A UAV inspecting transmission line insulators \cite{china}.}
  \label{uav}
\end{figure}

\subsubsection{Oil pipelines defects}
The damage of pipelines that transport petroleum and gas products lead to severe environmental problems. Eliminating breakthroughs and their consequences is expensive. To avoid accidents, it is recommended to improve diagnostics quality and to increase the frequency of in-line-inspection (ILI) tools deployment. ILI tools, also referred to as pipeline inspection gauges (Fig.~\ref{ris:ili}), use Hall effect for measuring localized Magnetic Flux Leakage (MFL) intensity along the pipe wall. While moving along the pipe gauge inspects the wall and detects the magnetic field leaks. MFL technique is the most common approach for oil and gas pipelines nondestructive testing nowadays.

\begin{figure}[ht]
	\center{\includegraphics[scale=0.22]{pipes/ili.png}}
	\caption{In-line-inspection tool}
	\label{ris:ili}
\end{figure}
The data collected during the inspection can be further analyzed for main diagnostics problems solving: damage and defects detection, their localization, diagnosis or defects classification.
Analysis results are useful for assets managing and repair priorities determination.

\subsection{Literature Review and Contributions}
In this section we shortly introduced the latest research background of insulators and pipelines diagnostics.

\subsubsection{Insulators}
Two different practices exist while processing  
insulators images, first segmenting them and the second to detect defections. 
In recent years, some studies have focused on these tasks \cite{a6,a7,a8,a9}. In study \cite{a6} a detection approach for transmission line insulators and their missing cap fault based on Faster Regions with convolutional neural network is introduced. The given approach consists of a CNN followed by a region proposal network and a object detector. Detection of the insulator images with the complex aerial background is also carried out in \cite{a7}. The model involves classic architecture of five modules of convolution and pooling, two modules of fully connected layers. The detection of the insulator is done along with and the recognition of explosion fault of insulators. Similarly, in study \cite{a8} cascading structure of CNN is proposed for the segmentation and fault detection of insulators. The proposed network only detects the missing cap defect of the insulators. An transmission network insulator recognition is investigated in \cite{a9}
where the segmentation algorithm is based on CNNs is proposed. In this study, the data-set is only utilized to segment and recognize the insulators and no defect detection is considered in the process.


Note that the aforementioned  studies either only focus on segmentation task or consider one type of defection (for instance missing cap). However, there are several common defections that can happen to any insulators. The most common types of faulty insulators can be categorized as: broken, burned, and missing cap ones. Example of which are shown in Fig.\ref{fig:mof}. 

Thus, in our project, we propose a two stage model which involves both tasks where we first segment the insulators from the taken images and then we detect the faulty ones if there is any. In our work, not only we classify the faulty insulators but also types of fault would be the output of the two stage model which separates our work form the studies carried out in the existing literature.

\begin{figure}[ht]
\begin{subfigure}{.48\linewidth}
  \centering
  \includegraphics[width=.8\linewidth]{Rahim/22-.jpg}  
  \caption{Healthy}
  \label{fig:sub-first}
\end{subfigure}
\begin{subfigure}{.48\linewidth}
  \centering
  \includegraphics[width=.8\linewidth]{Rahim/b9-.jpg}  
  \caption{Broken}
  \label{fig:sub-second}
\end{subfigure}\\
\begin{subfigure}{.48\linewidth}
  \centering
  \vspace{1ex}
  \includegraphics[width=.8\linewidth]{Rahim/bu10-.jpg}  
  \caption{Burned}
  \label{fig:sub-first}
\end{subfigure}
\begin{subfigure}{.48\linewidth}
  \centering
  \vspace{1ex}
  \includegraphics[width=.8\linewidth]{Rahim/mi2-.jpg}  
  \caption{Missing cap}
  \label{fig:sub-second}
\end{subfigure}
\caption{Modes of failure}
\label{fig:mof}
\end{figure}

\subsubsection{Pipelines}

Currently, the data obtained during the pipeline inspection process is primarily analyzed by traditional machine learning (ML) methods.
A comparison of performance among different ML methods for defects identification problem is presented in \cite{Khodayari-Rostamabad2009}.
The main challenge for this approach is creating informative and important features that will be used as an input for ML methods.
Usually, these diagnostics features are generated using expert knowledge and manually-created heuristics.
It imposes the limitation on defects detection problem solving quality.
A variety of most successful features is presented and analyzed in details in \cite{Slesarev2017}.

Deep Learning showed significant progress and achieved incredible results in numerous applications, just in the past few years.
The image classification problem is one of the most successful applications of DL and Convolutional Neural Networks (CNNs) in particular.
To automate the process of feature generation in MFL data analysis, CNNs can be used either.
As an advantage, they can solve the defects detection and segmentation tasks at the same time.
In literature there are examples of applying CNNs for defects detection \cite{Feng2017}, welds defect detection \cite{2020a}, welds and defects classification \cite{Yang2020}, defect size estimation \cite{Lu2019}.
For all mentioned applications, CNNs outperformed existing traditional approaches.
Nevertheless, still, there are just a few works dedicated to MFL data analysis using DL.
A number of particular problems that can be solved using a novel approach are not covered yet.
For instance, we could not find any works on applying CNNs to defects segmentation task, despite the importance of this problem solving according to \cite{Feng2017}.

In this work, we want to research two different problems:
\begin{enumerate}
    \item Defects detection (Image classification problem).
    \item Defects segmentation (Semantic segmentation problem).
\end{enumerate}

For their solving, we propose CNNs of different architectures and compare their results with existing state-of-the-art approaches.
Moreover, we research different preprocessing techniques for dealing with typical issues in the MFL data.



\section{Detection Approach}
In this section, the utilized CNN structures and further details of network models, applied augmentations, loss function and performance metrics for both task are introduced.

% We propose a model in this section in which we implement the segmentation and multiple fault classification for the power transmission insulators.
% The approach utilizes CNNs in a two-stage detection problem. First, the insulator/insulators are segmented from the rest of the image and then the insulator is classified to four possible categories: healthy, missing cap, broken cap, and burned cap.
% In the rest of this section, we give a detailed explanation of the CNN structures for segmentation and classification tasks and how the data augmentation is considered as preparation step of the data-set.


\subsection{CNN Preliminaries}

A CNN is a special type of a neural network that has proven  effective in computer vision applications. State-of-the-art results can be achieved in segmentation and classification tasks \cite{a10}. Compared to computer vision algorithms that do not take advantage of CNNs, much less pre-processing is required. More importantly, such networks are able to learn characteristics from data, which otherwise would have to be individually accounted for \cite{a11}.

Even though CNNs have been proposed in different architectures - to increase their efficiency for specific tasks and/or datasets, three different types of layers are used without exception, each with a specific propose: convolutional, pooling, and fully connected (linear) layers. The convolutional layers aim to extract feature maps of the input images by applying filters over different region of images. For instance, with $k$ filters, each filter having weight and bias of $w_i$ and $b_i$, respectively, the convolution of an image patch, $x_n$, can be written as follows:

\begin{equation}
f_{i,n}=\sigma(W_ix_n+b_i),
\end{equation}

where $\sigma$ is the activation function. Besides rectified linear units (ReLU), sigmoid or softmax activation functions, a multitude of different options exist, all having their individual advantages. These are applied on a layers's output neurons (e.g. after a convolutional layer).
After a number of convolutional layers, pooling layers are commonly applied in prominent network architectures to reduce the size of particular dimensions. Max-pooling and average-pooling are two examples. Pooling layers, alongside reducing dimensions's sizes, perform denoising when utilized on images. 
%Note, that max-pooling can execute denoising along with the dimensionality reduction task. 
% In the proposed CNN, presented in the next section, max-pooling is applied.
Fully connected layers are generally the last layers of CNNs, possessing a similar structure compared to the traditional neural networks\cite{a12}.
% In the following section the detection algorithm is going to be presented.

\subsection{Performance metrics}
Intersection over Union metric is  used  for the  segmentation  problem:
\begin{equation}
\begin{split}
    &I o U = \frac{T P}{(T P+F P+F N)}  = \\
    &= \frac{\sum_{i=0}^{N} 1_{\left\{\hat{y}_{i}=y_{i}=1\right\}}}
    {\sum_{i=0}^{N} 1_{\left\{\hat{y}_{i}=y_{i}=1\right\}} 
    + 1_{\left\{\hat{y}_{i}=1 ; y_{i}=0\right\}} 
    + 1_{\left\{\hat{y}_{i}=0 ; y_{i}=1\right\}}}
\end{split}
\end{equation}

For the classification problem we use accuracy defined as:$Acc = \frac{\sum_{i=0}^{N} 1_{\{\hat{y}_i=y_i\}}}{N},$
where $N$ - number of samples, $\hat{y}$ - predicted label, $y$ - true label.

\subsection{CNN Structure}
\subsubsection{Segmentation and Classification for transmission line insulators }
As discussed in the introduction section, the classification of the insulators requires two different yet closely related stages. First segmenting them from the background image and only then applying classification network on it with the goal of determining their states  (possible states are depicted in Fig. \ref{fig:mof}). 
Note that even though a single network may also be suggested to perform regarding the aforementioned task, in this project, we propose a modular detection algorithm  as presented in  Fig. \ref{fig:structure} to deal with the problem in hand.

The structure includes two distinct yet well-known CNNs. The first network is utilized in the first stage segmenting the insulators and the second network outputs the state of the insulator provided with the segmented insulator as input. Utilizing two networks in serial allows for easier implementation, as the segmentation and classification stages can be fine-tuned individually. Furthermore, a modular system facilitates replacing components in the data-processing step. 

\begin{figure*}[!h]
 \centering
  \includegraphics[width = 0.7\linewidth]{figs/FlowChart_rev.pdf}
  \caption{Structure of the fault detection algorithm}
  \label{fig:structure}
\end{figure*}

A CNN architecture that has proven effective for segmentation applications is the so-called UNet \cite{Ronneberger15}.
To classify the insulators' states, a VGG-like architecture is used \cite{Simonyan15}. First, a batch of input images is passed to the UNet. Its output is a batch of binary images, also known as as masks. Let $i$ denote an input image and $m$ denote the UNets output. If pixel $i(x,y),~\text{with}~
x,y \in W, H$ is part of an insulator, $m(x,y) = 1$, else $m(x,y) = 0$. Hence, $i\circ m$ yields an image with only the insulator(s) left. This reduces noise on the classification stage, because the image to classify only contains the component of interest.

\subsubsection{Defects detection and segmentation for oil pipelines}
Pipeline defect detection is also composed of two problems. First, the defect should be detected, and further, it should be evaluated using segmentation results.
We propose here two different CNNs for defect detection and defect segmentation.

For image classification, we used existing architecture that achieves best results in the MFL data classification problem and proposed novel CNN architecture to compare with the existing one.
We reimplemented CNN from \cite{Feng2017} with one difference: we used squared pictures (64x64 pixels) as an input, so we didn't implement Normalization layer (first layer in the Fig.~\ref{fig:CNN_feng2017}).

\begin{figure*}[!h]
 \centering
  \includegraphics[width = 0.9\linewidth]{pipes/CNN_feng2017.png}
  \caption{Architecture of CNN from \cite{Feng2017}}
  \label{fig:CNN_feng2017}
\end{figure*}
The interested reader can find all details and overall architecture parameters in \cite{Feng2017}.
From now on this CNN is marked as CNN-2 by the number of Convolutional layers.

Proposed model (Fig.~\ref{ris:CNN_our}) initially contains Dropout layers and Batch Normalization (BN) layers instead of Local Response Normalization (LRN) layers used in CNN-2.
\begin{figure*}[!h]
	\center{\includegraphics[scale=0.35]{pipes/CNN_our.png}}
	\caption{Architecture of the proposed CNN}
	\label{ris:CNN_our}
\end{figure*}
Our model consists of 5 Convolutional layers overall.
Each Convolutional layer is followed by BN and Dropout sequentially (not shown in Fig.~\ref{ris:CNN_our}).
All Convolutional layers have equal kernel size - 5 x 5.
All MaxPooling layers have equal kernel size - 2 x 2, and stride - 2.
From now on this CNN is marked as CNN-5.

When the classification or detection problem is solved, the segmentation problem is raised for determining the defect shape. It is worth mentioning the specifics of this task about initial picture size (64x64), which is fed to the network input. In this regard, a modified UNet \cite{Ronneberger15} was chosen as the baseline (Figure \ref{ris:UNet}). Even in this case, the picture size in the neck of the net is equal to 8x8.
\begin{figure}[ht]
	\center{\includegraphics[scale=0.5]{pipes/U_net.png}}
	\caption{Modified UNet architecture}
	\label{ris:UNet}
\end{figure}



% \begin{figure}[!h]
% \centering
%   \includegraphics[width=12cm,trim={0cm 0 0 0cm},clip]{processn1.pdf}
%   \caption{The flowchart of dataset preparation and training of the networks}
%   \label{train}
% \end{figure}

% \begin{figure}\label{dataset}
%     \centering
%     \begin{tabular}{lccccc}
%     	\begin{turn}{}\end{turn} &Healthy&Broken Cap \\
%     	\begin{turn}{}\quad  \end{turn}&
%     	\includegraphics[width=3.9cm]{Rahim/22-.jpg}&
% 		\includegraphics[width=3.9cm]{Rahim/b9-.jpg}&

		
% 	\end{tabular}
	
	
%     \begin{tabular}{lccccc}
% 	\begin{turn}{} \end{turn} &Burned Cap &Missing Cap\\
% 	\begin{turn}{ }\quad  \end{turn}&
% 	\includegraphics[width=3.9cm]{Rahim/bu10-.jpg}&
% 	\includegraphics[width=3.9cm]{Rahim/mi2-.jpg}&

% \end{tabular}
	
%     \centering\caption{The four possible categories of insulators in the classification task. }
%  \label{2dataset}   
% \end{figure}

\subsection{Loss functions}

Weighted Binary Cross-Entropy both for segmentation (pipelines) and detection problems:
\begin{equation}
\begin{split}
BCE &=-\frac{1}{N} \sum_{i=1}^{N} w_{1} \cdot y_{i} \cdot \log \left(p\left(\hat{y_{i}}\right)\right) \\
&+ w_{2} \cdot \left(1-y_{i}\right) \cdot \log \left(1-p\left(\hat{y_{i}}\right)\right)
\end{split}
\end{equation}
In addition MSE was used for segmentation of insulators:
\begin{equation}
 MSE = \frac{\sum_{i=1}^N |y_i - \hat{y_i}|^2}{N}
\end{equation}
 
\section{Dataset preparation}
In this section, not only we examine our approach to determine its capability in the both task of segmentation and defect classification but also we investigate other criteria as accuracy and speed in these tasks. In the remainder of this section, first experiment and data preparations are described in details and then the corresponding results are presented and discussed.


\subsection{Transmission line insulator dataset preparation}
In order to mimic the real-world behavior of how data is actually captured for analysis through the UAVs, we utilized directly the high-quality videos given by UAVs. These videos are taken by several companies throughout the world and are publicly accessible \cite{china,us}. This gives an advantage to our model, as when training is completed, the network can recognize several types of insulators utilized in different locations and companies all over the world. We rendered the videos to image sequences frame by frame. Therefore, the input images are high quality images captured in these videos. In the next step of the preparation, we created ground truth for the segmentation task. The original number of insulators images was 119 however, with the augmentation tools, it was increased to 9520. To do so, we used different types of augmentations by albumentation \cite{albu} such as HorizontalFlip, VerticalFlip, BrightnessContrast, and etc, complete list of which is given in Table \ref{tab:comp3}.  Also, some augmented images are shown in Fig.\ref{ris:aug_example1}.


We have three types of defection:  missing cap, broken cap, and burned cap samples of which are depicted in Fig. \ref{fig:mof}.  We also have separate types of augmentation applied for these images to have a sufficient number of images for this task. The number original images and augmented are specified in Table \ref{tab:table-name}. 


\begin{table}
\caption{Number of Insulator images before augmentation.}
\label{tab:table-name}
\begin{center}
\begin{tabular}{ |c|c|c| } 
\hline
Data & Classification & Segmentation  \\
\hline
\multicolumn{3}{|c|}{Before augmentation}\\
\hline
\multirow{1}{*}{Train-set} & 46 & 119  \\ 
\multirow{1}{*}{Validation-set} & 14 & 14 \\ 
\hline
\multicolumn{3}{|c|}{After augmentation}\\
\hline
\multirow{1}{*}{Train-set} & 3680 & 9520  \\ 
\multirow{1}{*}{Validation-set} & 14 & 14 \\
\hline
\end{tabular}
\end{center}
\end{table}
\subsection{Pipelines dataset preparation}
Although MFL data looks quite similar for different pipes and ILI tool types, it can differ significantly.
The data mainly depends on pipe size, wall width, sensors geometry, and other geometric characteristics.
Moreover, ILI tools differ a lot for different pipe sizes.
Therefore, the repeatability of the results for different datasets should be investigated additionally.
Following, we provide dataset characteristics.
We have data collected from the 219 mm in diameter pipe.
MFL dataset provides information about a single inspection tool run.
Dataset has 64 features collected as an array with a constant step along with the ILI tool movement inside the pipe.
Dataset has 4470704 samples that represent 15162.85 meters long pipeline part.
Sample values vary from 0 to 4095 units.
It has 745 defects of different types and 1462 welds, 34 of which are defected.
Fig.~\ref{ris:defect_example} shows examples of normal data, data with a weld, and with a defect.
Attached to the dataset technical report contains information about welds and defects location, defects types, sizes, and other related characteristics.
\begin{figure}[ht]
	\center{\includegraphics[scale=0.35]{pipes/1.png}}
	\caption{Example of the MFL data from pipelines dataset}
	\label{ris:defect_example}
\end{figure}

Raw data has several issues that don't allow us to solve CV problems without proper preprocessing.
They are:
\begin{enumerate}
	\item Sensors malfunctions (zeroed values cause bold horizontal line in Fig.~\ref{ris:defect_example});
	\item Displaced origins between data and reports coordinates;
	\item Inaccurate annotations, e.g., missed defects, wrong defect location, etc.
	\item No annotated data for the segmentation task.
\end{enumerate}

\subsubsection{Sensors malfunctions problem}
To deal with sensors malfunctions we suppose to fill the gaps (zeroed values) with values calculated by different methods.
Additionaly, we will consider values less than 2000 abnormal and replace them with zeroes during the preprocessing.
\begin{figure*}[!h]
	\center{\includegraphics[scale=0.39]{pipes/2.png}}
	\caption{Comparison of filling methods for missing values in pipelines dataset}
	\label{ris:filling_example}
\end{figure*}

\begin{figure}[!h]
	\center{\includegraphics[width=0.8\linewidth]{pipes/prepr.png}}
	\caption{Location of a weld: the black vertical line denotes a location of the weld, according to the report, while other lines represent values from sensors}
	\label{ris:prepr}
\end{figure}
\begin{figure}[!h]
	\center{\includegraphics[scale=0.50]{pipes/annot.png}}
	\caption{The methodology for obtaining the mask}
	\label{ris:annot}
\end{figure}
\begin{enumerate}
	\item Abnormal values are equal to 0. Then Min-Max scaling to $[0.5:1]$ range.
	\item Abnormal values are equal to the mean of normal values from one picture. Then Min-Max scaling.
	\item Abnormal values are equal to the mean of normal values over the column. Then Min-Max scaling.
	\item Abnormal values are equal to the mean of neighboring sensors over the column. Then Min-Max scaling.
	\item Abnormal values are equal to the interpolation results over the column. Then Min-Max scaling.
	\item Rerange initial set of values to 0...255 uint8 range.
	\item Rerange initial set of values to 0...1 float range \\ 
	(Fig.~\ref{ris:preproc_fun}). Such a specific function due to the range of normal operation of the sensor from 2500 to 3500 units.
\end{enumerate}

\begin{figure}[ht]
	\center{\includegraphics[scale=0.22]{pipes/preproc_fun.png}}
	\caption{The function for converting the initial values of signal to the input of network}
	\label{ris:preproc_fun}
\end{figure}

The results of applied methods are presented in Fig.~\ref{ris:filling_example}.


Min-Max scaling can be applied using whole dataset or just one image.
Both approaches will be compared during the experiment conducting.

\subsubsection{Displaced origins problem}
Since the ILI tool location data did not match the defect location data from the report, it was necessary to merge the data. The key factor here turned out to be that signal values from magnetic flux sensors grow at the weld site (Figure \ref{ris:prepr}). 



The solution was to find the locations of the maxima of sensors data values and then to combine it with the weld coordinates.

\subsubsection{Inaccurate annotations problem}
This problem is a common one for oil and gas pipeline nondestructive testing \cite{Khodayari-Rostamabad2009}.
It appears to be a lot of missing defects that affects the quality of the problem.
Besides, there are wrong defect types and locations.
To eliminate wrong location issue, we additionally searched extremums around the provided location and chose the defects or welds taking into account new coordinates.

\subsubsection{Manual annotations for the segmentation task}
Since there was no annotated data for the segmentation problem, it was necessary to annotate it manually (Figure \ref{ris:annot}). The characteristics of the obtained dataset can be seen in Table~\ref{tab:alg1}.


\subsubsection{Augmentation}
Although we have a lot of data, we don't have a lot of defects and welds in comparison with normal pipe wall instances.
We use the augmentation procedure to balance classes of pictures and increase the model's quality by increasing the number of instances in small classes (defects, welds).
For this dataset we also use Albumentations \cite{albu} as an augmentation tool.
All applied augmentations both for welds and defects are presented in Table~\ref{tab:comp3}.
Examples of augmentations results are shown in Fig.~\ref{ris:aug_example}.
% \begin{figure}[ht]
% 	\center{\includegraphics[scale=0.3]{pipes/4.png}}
% 	\caption{Examples of the augmentation results}
% 	\label{ris:aug_example}
% \end{figure}

% \begin{figure}[ht]
% \begin{subfigure}{\linewidth}
%   \centering
%   \includegraphics[scale=0.3]{pipes/4.png}
%   \caption{Pipelines Dataset}
%   \label{ris:aug_example}
% \end{subfigure}\\
% \begin{subfigure}{\linewidth}
%   \centering
% %   \vspace{1ex}
%   \includegraphics[scale=0.3]{Rahim/Aug.jpg}
%   \caption{Insulators Dataset}
% %   \label{fig:vggtrain1}
% \end{subfigure}
% \caption{Examples of the augmentation results}
% \label{Ins:aug_example}
% \end{figure}

The characteristics of the pipeline defects dataset are described in Table \ref{tab:alg1}, where * symbol indicates a random call function 5 and 6 from the defects augmentation list, so the exact number is unknown. %№
\begin{table}[!htb]
	\caption{\label{tab:alg1}Dataset size for pipeline defects detection and segmentation problems}
	\begin{center}
		\small
		\begin{tabular}{| c | c  c  c | c  c |}
			\multicolumn{1}{c}{} & \multicolumn{3}{c}{Classification} & \multicolumn{2}{c}{Segmentation} \\
			\hline
			Data & Normal & Defect & Weld & Normal & Defect \\
			\hline
			\multicolumn{6}{|c|}{Before augmentation}  \\
			\hline
			Train  & 11106 & 569 & 1130 & 181 & 450 \\
			Validation & 584 & 142 & 282 & 33 & 111 \\
			\hline
			\multicolumn{6}{|c|}{After augmentation}  \\
			\hline
			Train  & 11106 & 8535 & 11300 & * & * \\
			Validation & 584 & 142 & 282 & * & * \\
			\hline
		\end{tabular}
	\end{center}
\end{table}


\begin{table}[!htb]
    \caption{Augmentation Table.}
    \begin{center}
    \small
        \begin{tabular}{ |p{3cm}||p{1.2cm}|p{1.2cm}|p{1.2cm}|  }
        \hline
        Augmentation Types & Insulators & Pipelines (welds) & Pipelines (defects) \\
        \hline
        Rotate & - &  p=1 & p=1 \\
        VerticalFlip & p=0.5 & p=1 & p=1 \\
        HorizontalFlip & p=0.5 & p=1 & p=1 \\
        ElasticTransform & p=0.5 & p=1 & p=1 \\
        GridDistortion & p=0.5 & p=1 & p=1 \\
        OpticalDistortion & p=0.8 & p=1 & p=1 \\
        Transpose & - & - & p=1 \\
        RandomRotate90 & p=0.5 & - & p=1 \\
        CLAHE & p=0.8 & - & - \\
        RandomBrightness &p=0.5&-&-\\
        RandomContrast&p=0.5&-&-\\
        RandomGamma & p=0.8 &  - & - \\
        \hline
        \end{tabular}
    \label{tab:comp3}
    \end{center}
\end{table}
\begin{figure}[!h]
\begin{subfigure}{\linewidth}
  \centering
  \includegraphics[scale=0.3]{pipes/4.png}
  \caption{Pipelines Dataset}
  \label{ris:aug_example}
\end{subfigure}\\
\begin{subfigure}{\linewidth}
  \centering
%   \vspace{1ex}
  \includegraphics[scale=0.3]{Rahim/Aug.jpg}
  \caption{Insulators Dataset}
  \label{ris:aug_example1}
\end{subfigure}
\caption{Examples of the augmentation results}
\label{Ins:aug_example}
\end{figure}



\section{Experiments} 
\subsection{Transmission line insulator}
%\subsection{Insulator Dataset Results} % I think it’s better to use it because in theory, we should show the process.
As mentioned in the previous subsection, the structure of the CNN to detect faults includes two different CNNs.
As shown in the illustration, the output of the UNet (a binary mask) is passed to the VGG, alongside the input image, for classification. Thus, the classification returned by the VGG is dependent on the segmentation result of the UNet.
% As shown in equation \textbf{REF}.
Training UNet is straight forward as it can be trained by considering the available  ground truth of the target masks.
However, for training the classification network two approaches can be investigated:
% Since, to train the UNet, ground truths for segmentation are available in the training and validation data set, two different training methods were tested:
\begin{itemize}
    \item Training UNet and VGG independently
    \item Training VGG on UNet's (trained) output
\end{itemize}
In the remainder of this subsection, we first investigate UNet (segmentaion) training  and its performances and then the result of both approaches for classification stage training are discussed.
\subsubsection{UNet training} 

Since, the original dataset is captured from several videos with different background and number of the images is rather low, we propose training to be carried in two sequence which guarantees a better training result and performance in the end. These two sequences are depicted in Fig.\ref{fig:unettrain}. As can be seen from this figure in the second sequence lower losses are achieved for the validation set. Note that the depicted loss is calculated over batch thereby including some fluctuation, however, only the best performance is saved and utilized in the next steps. Several stage of the training and the related outputs are depicted in Fig.\ref{fig:iou}. We also investigated a threshold where UNet can preform its best performance considering maximum IoU metric as shown in Fig.\ref{fig:iou1}. The Trained segmentation network could reach the IoU of 0.795 in segmenting the insulators from the main images. Some of the final segmentation network results and produced masks are depicted in the Fig.\ref{fig:seg}. As can be seen, the trained UNet  performs satisfactory in segmentation of power transmission insulators. 

\begin{figure}[ht]
\begin{subfigure}{\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figs/Segmentation1.pdf}
  \caption{Training sequence 1}
  \label{fig:vggtrain1}
\end{subfigure}\\
\begin{subfigure}{\linewidth}
  \centering
  \vspace{1ex}
  \includegraphics[width=
  \linewidth]{figs/Segmentation2.pdf}  
  \caption{Training sequence 2}
  \label{fig:vggtrain1}
\end{subfigure}
\caption{UNet training}
\label{fig:unettrain}
\end{figure}

\begin{figure}[ht]
	\center{\includegraphics[width=\linewidth]{figs/unet_output_training.png}}
	\caption{Output of the proposed UNet architecture at different stages in the training process (100, 500, 1200 and 2200 iterations)}
	\label{fig:iou}
\end{figure}

\begin{figure}[ht]
	\center{\includegraphics[width=\linewidth]{figs/IoU.pdf}}
	\caption{IoU as a function of thresholds $p$}
	\label{fig:iou1}
\end{figure}

\begin{figure}[!h]
\centering
\begin{subfigure}{.25\linewidth}
  \includegraphics[width=\linewidth]{figs/a-0.jpg}  
  \label{fig:sub-first}
\end{subfigure}
\begin{subfigure}{.25\linewidth}
  \includegraphics[width=\linewidth]{figs/0.jpg}  
  \label{fig:sub-second}
\end{subfigure}
\begin{subfigure}{.25\linewidth}
  \includegraphics[width=\linewidth]{figs/b-0.jpg}  
  \label{fig:sub-second}
\end{subfigure}\\
\begin{subfigure}{.25\linewidth}
  \includegraphics[width=\linewidth]{figs/a-11.jpg}  
  \label{fig:sub-first}
\end{subfigure}
\begin{subfigure}{.25\linewidth}
  \includegraphics[width=\linewidth]{figs/11.jpg}  
  \label{fig:sub-second}
\end{subfigure}
\begin{subfigure}{.25\linewidth}
  \includegraphics[width=\linewidth]{figs/b-11.jpg}  
  \label{fig:sub-second}
\end{subfigure}\\
\begin{subfigure}{.25\linewidth}

  \includegraphics[width=\linewidth]{figs/org.jpg}  
  \label{fig:sub-first}
  \caption{Healthy}
\end{subfigure}
\begin{subfigure}{.25\linewidth}
  \includegraphics[width=\linewidth]{figs/seg.jpg}  
  \label{fig:sub-second}
  \caption{Mask}
\end{subfigure}
\begin{subfigure}{.25\linewidth}
  \includegraphics[width=\linewidth]{figs/final.jpg}  
  \label{fig:sub-second}
  \caption{Segmented}
\end{subfigure}
\caption{Segmentation results for transmission insulators}
\label{fig:seg}
\end{figure}



\subsubsection{VGG}

Since the prediction for the proposed network structure is computed as $y' = \mathrm{VGG}(\mathrm{U\text{-}Net}(x), x)$, the classification result is dependent on the output of the segmenting unit. Two different types of training were conducted. First, the VGG was trained on the ground truth segmentation mask. The obtained loss through the explained regime is shown in Fig.\ref{fig:vggtrain}. SGD was chosen as an optimizer, with a learning rate of 0.008 and a momentum of 0.26. Furthermore, a multiplicative scheduler was employed multiplying the learning rate by 0.98 after every global step. With the exogenous ground truth the obtained classification network accuracy is 0.92.
As shown in table \ref{tab:alg1} however, utilizing both independently trained networks yields a mere 21\% accuracy. This suggests that classification, as outlined, highly depends on the result of segmentation network. Training these components independently leads to poor outcomes. 
Secondly, the classifier was trained on segmentation results produced by the trained U-Net. 

\begin{figure}[ht]
	\center{\includegraphics[width=\linewidth]{figs/VggLoss_final.pdf}}
	\caption{VGG training on correct ground truth}
	\label{fig:vggtrain}
\end{figure}

Improved results were obtained by training the classifier on the output of the segmentation stage, as specifics  proceeding of CNN could be considered. Note, that getting acceptable training result proved difficult, due to limitations (especially in size) of the created dataset. Moreover, the dataset is very diverse. Thus, several training approaches were investigated.
\subsubsection{Pre-training}
CNNs are non-convex functions. The training success can be highly dependent on the starting point of the optimization. Rather than initializing the network randomly, a starting point can be supplied by loading model weights. In the following, pre-training means setting the model's weights to the result obtained, by training the VGG on ground truth data. This had positive affects on the consecutive training on segmentation results.
\subsubsection{Reset and Alteration}
The training was conducted in two nested for-loops, looping over outer and inner epochs. After looping over all inner epochs, adjustments were made to the optimizer.
The first technique that proved successful was resetting the solver to its initial state. This prevented diminishing improvements when a local minimum was reached, or the learning rate became too small. This regularly facilitated finding an even better solution after a reset.
Secondly, it was tried alternating between optimizers with different settings, in the same manner. This technique however, turned out to be less effective.

\begin{figure}[ht]
	\center{\includegraphics[scale = 0.36]{figs/pseudo.png}}
	\caption{Pseudo-code of resetting and altering the solver during training}
	\label{fig:pseudo}
\end{figure}

 For instance, the obtained loss values in training is depicted in Fig.\ref{fig:vggtrain1} where no pre-training or solver resetting is utilized. It is clear increasing training iteration has no effect in decreasing validation loss. While applying these two as shown in Fig.\ref{fig:vggtrain0} could lead to much better results as the minimum validation loss gradually decreases over training iterations. A better comparison is provided in Fig.\ref{fig:vggtrain1} in which the minimum losses achieved by each investigated approach are demonstrated.
Finally, the acquired accuracy by combination of the aforementioned approaches is concluded in Table \ref{tab:alg1}. 

\begin{figure}[ht]
\begin{subfigure}{\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figs/PretrainedReset_final.pdf}
  \caption{Pre-training and solver reset}
  \label{fig:vggtrain0}
\end{subfigure}\\
\begin{subfigure}{\linewidth}
  \centering
  \vspace{1ex}
  \includegraphics[width=
  \linewidth]{figs/notPretrainedNoReset_final.pdf}  
  \caption{No pre-training and no solver reset}
  \label{fig:vggtrain1}
\end{subfigure}
\caption{VGG training on UNet}
\label{fig:vgg_unet}
\end{figure}


\begin{table}[!htb]
	\caption{The obtained accuracy results for different training regime of VGG based on UNet outputs (4800 global iterations)}
	\label{tab:alg1}
	\begin{center}
		\small
		\begin{tabular}{| c | c  c  c | c  |}
		  %  \hline
		  %  \multicolumn{4}{|c|}{\textit{VGG trained on ground truth}} & 0.21\\
		    \hline
			\# Training & Pre-trained & Reset & Alternating & $Acc$ \\
			\hline
			1  & x & - & - & 0.42\\
			2  & - & x & - & 0.5\\
			3  & x & - & x & 0.71\\
			4  & x & x & - & \textbf{0.78}\\
			\hline
		    \multicolumn{4}{|c|}{\textit{Separated VGG and UNet training}} & 0.21\\
		    \hline
		\end{tabular}
	\end{center}
\end{table}

\subsection{Pipelines}
\subsubsection{Defects detection problem}

We present the results of comparison for different preprocessing techniques and different CNN architectures for binary classification (normal pipe wall or defect/weld) in Tab.~\ref{tab:comp1} and multiclass classification problem (normal pipe wall, defect or weld) in Tab.~\ref{tab:comp2}.

Batch size is equal to 64, so the input to the network has shape (64, 1, 64, 64).
For all experiments, we use Adam optimizer with initial learning rate 0.001 and learning rate scheduler with parameters: threshold = 0.0001, factor = 0.5, min lr = 0.0001, patience = 484.
Also, for all experiments, the number of epochs is equal to 12.
Dropout rate for all experiments is equal to 0.33.
All mentioned parameters were selected by using grid search procedure.

\begin{table}[!htb]
	\caption{\label{tab:comp1}Comparison of performance among different classification methods for binary classification problem. $\hat{y}=y=0$ - normal; $\hat{y}=y=1$ - defect/weld.}
	\begin{center}
		\small
		\begin{tabular}{| l | c | c | c |}
			\hline
			Method & $\hat{y}=y=0$& $\hat{y}=y=1$  & Average \\
			\hline
			CNN-2 & 95.55 & 82.08 & 89.88 \\
			CNN-5 & 97.95 & \textbf{91.51} & \textbf{95.24} \\
			CNN-5+LRN & \textbf{98.29} & 89.86 & 94.74 \\
			\hline
			\multicolumn{4}{|c|}{Filling techniques comparison}  \\
			\hline
			\parbox[l]{2.6cm}{CNN-5 (filling 1)}  & 97.95 & \textbf{91.51} & \textbf{95.24}\\
			\parbox[l]{2.6cm}{CNN-5 (filling 2)}  & 97.95 & 84.20 & 92.16 \\
			\parbox[l]{2.6cm}{CNN-5 (filling 3)}  & 97.26 & 83.02 & 91.27 \\
			\parbox[l]{2.6cm}{CNN-5 (filling 4)}  & \textbf{98.63} & 81.13 & 91.27 \\
			\parbox[l]{2.6cm}{CNN-5 (filling 5)}  & 98.12 & 81.84 & 91.27 \\
			\hline
			\multicolumn{4}{|c|}{Centering influence for the first filling method}  \\
			\hline
			\parbox[l]{2.6cm}{CNN-5 (centered)}  & 97.95 & \textbf{91.51} & 95.24 \\
			\parbox[l]{2.6cm}{CNN-5 (not centered)}  & \textbf{98.46} & 91.27 & \textbf{95.44} \\
			\parbox[l]{2.6cm}{CNN-2 (centered)}  & 95.55 & 82.08 & 89.88 \\
			\parbox[l]{2.6cm}{CNN-2 (not centered)}  & 96.92 & 80.42 & 89.81 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}
\begin{table}[!htb]
	\caption{\label{tab:comp2}Comparison of performance among different classification methods for multiclass classification problem. $\hat{y}=y=0$ - normal; $\hat{y}=y=1$ - defect; $\hat{y}=y=2$ - weld.}
	\begin{center}
		\small
		\begin{tabular}{| l | c | c | c | c |}
			\hline
			Method & $\hat{y}=y=0$ & $\hat{y}=y=1$ & $\hat{y}=y=2$  & Average \\
			\hline
			CNN-2 & 97.60 & 59.86 & 92.91 & 90.97 \\
			CNN-5 & \textbf{98.12} & \textbf{76.76} & \textbf{98.23} & \textbf{95.14} \\
			\hline
			\multicolumn{5}{|c|}{Centering influence for the first filling method}  \\
			\hline
			\parbox[l]{1.6cm}{CNN-5 (centered)}  & \textbf{98.12} & \textbf{85.21} & 75.18 & 89.88 \\
			\parbox[l]{1.6cm}{CNN-5 (not centered)} &  \textbf{98.12} & 76.76 & \textbf{98.23} & \textbf{95.14} \\
			\parbox[l]{1.6cm}{CNN-2 (centered)}  & 96.75 & 71.13 & 52.13 & 80.65 \\
			\parbox[l]{1.6cm}{CNN-2 (not centered)}  & 97.60 & 59.86 & 92.91 & 90.97 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

Filling methods were researched for binary classification problem.
Centering means using peaks (extremums) searching procedure for welds or defects correct coordinates defining.
The centering procedure was researched both for binary and multiclass classification problems.
Moreover, Min-Max normalization using either a single image or whole dataset was investigated.
Finally, CNN-2 and CNN-5 were compared for centered images with the first filling method using single image Min-Max normalization.


\subsubsection{Defects segmentation problem}

The selection of hyperparameters was performed for a baseline net. 
In Fig. \ref{ris:heatmaphyper}, it can be seen the best results which were gotten on Validation set on the 50 epochs. 
\begin{figure}[ht]
	\center{\includegraphics[scale=0.35]{pipes/heatmaphyper.png}}
	\caption{Table of hyperparameters}
	\label{ris:heatmaphyper}
\end{figure}
The best hyperparameters in our case are learning rate = 0.004, batch size = 32

It is worth introducing some terms that will be used further in the text.

UnetDownBlock is sequential execution of the following elements: 
\begin{itemize}
    \item 2d Convolution 
    \item ReLU 
    \item 2d Convolution 
    \item ReLU 
    \item Max pooling
\end{itemize}
UnetUpBlock is sequential execution of the following elements: 
\begin{itemize}
    \item upsampling
    \item concatenation
    \item 2d Convolution 
    \item ReLU 
    \item 2d Convolution 
    \item ReLU 
\end{itemize} 

The influence of the number of channels in convolution layers on the network results also was analyzed. Validation loss curves for this experiment is showed in Fig.~\ref{ris:struc1}, where n\_base\_channel is the number of channels after the first convolution layer. In each next UnetDownBlock block, the number of channels doubled toward the previous one.
It can be seen from the figure that the best case was when there were 32 channels from one input channel to the output, followed by doubling in each UnetDownBlock block. This architecture is different from the baseline and the classic UNet \cite{Ronneberger15}.
\begin{figure}[ht]
	\center{\includegraphics[scale=0.16]{pipes/struc1.png}}
	\caption{Comparison of architectures with different numbers of channels in Convolution layers of UNet}
	\label{ris:struc1}
\end{figure}

Then, architectures with a different number of UnetDownBlock and UnetUpBlock blocks were analyzed. Validation loss curves for this experiment are shown in Fig.~\ref{ris:add_block}. A distinctive characteristic is that in architectures with 1 and 2 additional blocks, the size of the image in the neck becomes 4x4 and 2x2, respectively.
\begin{figure}[ht]
	\center{\includegraphics[scale=0.3]{pipes/add_block.png}}
	\caption{Comparison of architectures with additional UnetDownBlock and UnetUpBlock blocks}
	\label{ris:add_block}
\end{figure}
The figure shows that the best architecture with the same number of blocks as the baseline.

The final results for more accurate architecture is shown in Fig.~\ref{ris:mainresult}
\begin{figure}[ht]
	\center{\includegraphics[scale=0.35]{pipes/quadro.png}}
	\caption{The main results for defect segmentation in pipelines}
	\label{ris:mainresult}
\end{figure}

The final result of the intersection over the union is 0.2, while the baseline is 0.17.


\section{Conclusion}
Insulators and oil pipelines are known to be an important component of the
energy transmission systems. Yet on the other hand they are exposed to electrical, mechanical, and environmental stresses leading to different kind of defection. In this study, we focused on investigating approaches based on the deep learning techniques to detect and classify defected insulators and detect the defects in pipelines. In doing so, we utilized state-of-art CNNs such as UNets and VGG modified to match the task in hand. Multiple improvement of the existing literature were offered in this project. In spite of the previous works in the literature which were focused on a particular failure mode or defect of insulators, we had three different defects namely, insulators with: broken, burned and missing cap. The results showed successful performance of the trained UNet in segmentation task of insulators and the trained VGG as the second stage network in reaching a proper accuracy while classifying insulators into the possible considered classes. Also, the network (CNN-5) that outperformed currently used CNNs for defect detection of pipelines was proposed. Moreover, we proposed a modified UNet for defects of pipelines segmentation. The results of segmentation show the applicability of the proposed UNet for the size of defects evaluation. The results of the experiments prove that all parts of the oil pipeline diagnostics process can be fully automated with high quality.

Finally, there can be defined several project development options:
\begin{enumerate}
    \item increasing sizes of the datasets;
	\item improving preprocessing procedures, including manual pictures selection;
	\item multiclass defects classification for pipelines dataset;
	\item defected and healthy welds classification for pipelines dataset;
	\item defect depth evaluation for pipelines dataset;
	\item investigate the repeatability of the results for similar datasets.
\end{enumerate}

\section{Contribution}

Vyacheslav Kozitsin:  His main task was to solve problem of semantic segmentation of defects in pipes.  Outcomes: A baseline was chosen as a stripped-down version of UNet (Fig.~\ref{ris:UNet}). The specifics of applying UNet under conditions of small sizes of the original image (64x64) were investigated. As a result, the problem was solved with IoU=0.2 and good visual results (Fig.~\ref{ris:mainresult}). Concomitant successes: annotated the data for the defect segmentation of pipe (Table~\ref{tab:alg1}); proposed own approach to the preprocessing of raw data from sensors based on expert knowledge (Fig.~\ref{ris:preproc_fun}); solved the problem of displaced origins between data and report files (Fig.~\ref{ris:prepr}). Active participation in the filling of the report and presentation.

Iurii Katser:
His main task was to solve the defects detection problem for the oil pipeline dataset.
Exploratory Data Analysis (EDA) was provided.
EDA allowed us to define issues in data that impede CV problems solving without data preprocessing.
Data preprocessing tools were implemented (abnormal values filling, defects, and welds coordinates searching).
The influence of different preprocessing algorithms was analyzed and presented in the results section.
The CNN (CNN-5) that overperformed the best existing network on the presented pipelines dataset was proposed.
Outcomes and future work were marked.

Rahim Tariverdi:
His main task was to prepare the dataset for classification of insulators problem. The task required lots of time as there was no proper images existed on the faulty insulators. So each images according to the considered fault were photoshoped to present different types of faulty insulators. Example of the created images for dataset are available in Fig.~\ref{fig:mof} of the report. 
The other contribution includes active participation in the group meeting and discussion, creating several figures and tables in the project and the final presentation.
% At first step of every Deep Learning project, we always need to have a dataset that contains a handful number of great images that can be used to build computer vision (CV) models. In our sub-subject (Transmission line insulator faults) we haven’t had access for such dataset so we had to first collect available videos on the interne(Fig.~\ref{uav}) and using some rendering applications, generate their frames and then making ground truth for corresponding images by Photoshop. However, this was enough for Semantic Segmentation part; the next step was Classification part which we wanted to separate healthy insulators from different types of defected insulators such as burned, missed cap and broken ones. The problem again was that we didn’t have enough images from defected insulator so we had to make them as well(Fig.~\ref{fig:mof}).

Arman Alahyari:
His main task was to develop segmentation stage model to  segment the insulators from the images in the dataset utilizing UNet structure. The final result led to the IoU of 0.795. Some example segmentation are available in Fig.\ref{fig:seg}.
Other contribution includes 
dataset preparation for the segmentation task (rendering videos into image sequences and creating ground truth by photoshop), writing and structuring the final report for insulator related sections, and active participation in group meeting and final presentation.

Anton Hinneck:
His main task was to classify the segmented insulators into the four possible modes of failure, utilizing a VGG-like architecture. At the end with proper training approach an accuracy of 0.78 was acquired noticeably higher than baseline training approaches.
He developed the data structure for unified data management at all stages of the experiment and created plots.
Other contributions include active participation in group meetings, writing the report and result figures and the final presentation.
\section{Third party code}
\begin{itemize}
    \begin{itemize}
        \item  Augmentation \url{https://pastebin.com/BunFVpTE}. The code has been changed by adding our methods. The purpose of the use is structure of random execution of functions.
        \item Weighted Binary Cross Entropy function. \url{https://discuss.pytorch.org/t/solved-class-weighed-binary-crossentropy-not-working-even-with-equal-weights/47055}. The code has been changed. 
        \item UNet code realization from the Deep Learning 2020 seminar. Changed for the purpose of the project.
    \end{itemize}
    
\end{itemize}

\section{Repository with our code}
The code is available at the following link:
\url{https://github.com/waico/CV-for-anomaly-detection-in-industrial-applications}

\bibliographystyle{IEEEtran}
\bibliography{ref.bib}
\end{document}
